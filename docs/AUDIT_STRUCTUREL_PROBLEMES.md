# Audit Structurel - Probl√®mes Identifi√©s

**Date** : 2025-12-22  
**Statut** : üî¥ CRITIQUE - Probl√®mes structurels profonds  
**Priorit√©** : üî¥ HAUTE

---

## üìã TODO Liste Professionnelle

### üî¥ CRITIQUE - Probl√®mes Bloquants

#### 1. **Synchronisation Texte/TTS Cass√©e**
- **Sympt√¥me** : Le TTS ne finit pas de dire ce qui est √©crit
- **Cause** : En mode streaming, le texte complet n'est jamais r√©cup√©r√© pour le TTS
- **Fichiers concern√©s** :
  - `interface/qaia_interface.py` : `_on_llm_complete()` ne r√©cup√®re pas le texte complet
  - `interface/components/streaming_text.py` : `StreamingTextDisplay` n'expose pas le texte complet
  - `agents/callbacks/streaming_callback.py` : `on_llm_end()` re√ßoit la r√©ponse mais ne l'√©met pas
- **Impact** : TTS lit seulement une partie du texte affich√©
- **Solution** : Stocker le texte complet dans `StreamingTextDisplay` et le r√©cup√©rer dans `_on_llm_complete()` pour le TTS

#### 2. **R√©p√©tition Forc√©e de la Pr√©sentation**
- **Sympt√¥me** : "Je suis QAIA, votre assistante multimodale intelligente et de qualit√©" r√©p√©t√©e avant chaque r√©ponse
- **Cause** : Prompt syst√®me ligne 100 dans `config/system_config.py` force cette pr√©sentation
- **Fichiers concern√©s** :
  - `config/system_config.py` : Ligne 100 `"Quand tu te pr√©sentes, tu dois dire..."`
  - `agents/llm_agent.py` : Construction du prompt syst√®me
- **Impact** : R√©p√©tition inutile, verbosit√© excessive
- **Solution** : Modifier le prompt pour ne se pr√©senter qu'une seule fois (premi√®re interaction)

#### 3. **Doublons "(HH:MM) QAIA:" Persistants**
- **Sympt√¥me** : Les doublons `(15:54) QAIA: QAIA:` persistent malgr√© le nettoyage
- **Cause** : 
  - Le mod√®le g√©n√®re ces pr√©fixes dans sa r√©ponse
  - Le nettoyage est appliqu√© APR√àS la g√©n√©ration, mais le mod√®le continue de les g√©n√©rer
  - Le prompt syst√®me peut encourager cette g√©n√©ration
- **Fichiers concern√©s** :
  - `agents/rag_agent.py` : Nettoyage apr√®s g√©n√©ration
  - `interface/qaia_interface.py` : Nettoyage avant affichage
  - `config/system_config.py` : Prompt syst√®me
- **Impact** : Affichage incoh√©rent, confusion utilisateur
- **Solution** : 
  - Modifier le prompt pour interdire explicitement ces pr√©fixes
  - Am√©liorer le nettoyage pour √™tre plus agressif
  - Ajouter un post-traitement de correction

#### 4. **Fautes d'Orthographe dans les R√©ponses**
- **Sympt√¥me** : "dran" au lieu de "de", "lorsqueil" au lieu de "lorsqu'il"
- **Cause** : Le mod√®le Phi-3 g√©n√®re des erreurs d'orthographe (limitation du mod√®le)
- **Fichiers concern√©s** :
  - `agents/rag_agent.py` : Post-traitement des r√©ponses
  - `interface/qaia_interface.py` : Post-traitement avant affichage/TTS
- **Impact** : Qualit√© de r√©ponse d√©grad√©e, professionnalisme affect√©
- **Solution** : Ajouter un correcteur orthographique fran√ßais (pyspellchecker ou language-tool-python)

### üü° MOYEN - Probl√®mes de Qualit√©

#### 5. **Flux de Traitement Incoh√©rent**
- **Sympt√¥me** : Incoh√©rences entre streaming, affichage et TTS
- **Cause** : Plusieurs chemins de traitement (streaming vs non-streaming) avec logique diff√©rente
- **Fichiers concern√©s** :
  - `qaia_core.py` : `process_message()` retourne la r√©ponse
  - `interface/qaia_interface.py` : `_process_text_thread()` g√®re l'affichage et TTS
  - `agents/rag_agent.py` : G√©n√©ration avec/sans RAG
- **Impact** : Comportement incoh√©rent, bugs difficiles √† reproduire
- **Solution** : Unifier le flux de traitement avec un seul point de sortie pour affichage/TTS

#### 6. **Post-Traitement des R√©ponses Incomplet**
- **Sympt√¥me** : Nettoyage appliqu√© √† des endroits diff√©rents avec des r√©sultats diff√©rents
- **Cause** : Nettoyage dupliqu√© dans `rag_agent.py` et `qaia_interface.py`
- **Fichiers concern√©s** :
  - `agents/rag_agent.py` : Nettoyage apr√®s g√©n√©ration
  - `interface/qaia_interface.py` : Nettoyage avant affichage
- **Impact** : Incoh√©rences, code dupliqu√©
- **Solution** : Centraliser le post-traitement dans une fonction unique

---

## üîç Analyse D√©taill√©e des Probl√®mes

### Probl√®me 1 : Synchronisation Texte/TTS

**Flux actuel (CASS√â)** :
```
LLM g√©n√®re ‚Üí StreamingCallback.on_llm_new_token() ‚Üí Event Bus 'llm.token' 
‚Üí qaia_interface._on_llm_token() ‚Üí StreamingTextDisplay.append_token()
‚Üí StreamingCallback.on_llm_end() ‚Üí Event Bus 'llm.complete'
‚Üí qaia_interface._on_llm_complete() ‚Üí StreamingTextDisplay.complete_generation()
‚Üí qaia_core.process_message() retourne response
‚Üí qaia_interface._process_text_thread() utilise response pour TTS
```

**Probl√®me** : `response` dans `_process_text_thread()` est la r√©ponse finale du LLM, mais si le streaming est actif, le texte affich√© dans `StreamingTextDisplay` peut √™tre diff√©rent (tokens accumul√©s). Le TTS utilise `response` qui peut √™tre tronqu√© ou diff√©rent.

**Solution** : 
1. Stocker le texte complet dans `StreamingTextDisplay` pendant le streaming
2. Dans `_on_llm_complete()`, r√©cup√©rer le texte complet depuis `StreamingTextDisplay`
3. Utiliser ce texte complet pour le TTS

### Probl√®me 2 : R√©p√©tition de la Pr√©sentation

**Cause** : Ligne 100 dans `system_config.py` :
```python
"Quand tu te pr√©sentes, tu dois dire ¬´ Je suis QAIA, votre assistante multimodale intelligente et de qualit√© ¬ª."
```

Le mod√®le interpr√®te "Quand tu te pr√©sentes" comme "√† chaque fois que tu r√©ponds", pas "une seule fois au d√©but".

**Solution** : Modifier le prompt pour :
- Se pr√©senter UNIQUEMENT lors de la premi√®re interaction
- Ne pas r√©p√©ter la pr√©sentation dans les r√©ponses suivantes
- Utiliser un flag de contexte pour savoir si c'est la premi√®re interaction

### Probl√®me 3 : Doublons "(HH:MM) QAIA:"

**Cause** : Le mod√®le Phi-3 g√©n√®re naturellement des pr√©fixes de formatage. Le nettoyage regex ne capture pas tous les cas.

**Solution** :
1. Ajouter dans le prompt syst√®me : "NE JAMAIS inclure de pr√©fixes comme '(HH:MM) QAIA:' ou 'QAIA:' dans tes r√©ponses"
2. Am√©liorer le nettoyage pour √™tre plus agressif (multi-passes, insensible √† la casse)
3. Ajouter un post-traitement qui supprime TOUS les pr√©fixes avant affichage/TTS

### Probl√®me 4 : Fautes d'Orthographe

**Cause** : Limitation du mod√®le Phi-3 (3.8B) qui g√©n√®re parfois des erreurs d'orthographe.

**Solution** : Ajouter un correcteur orthographique fran√ßais :
- Utiliser `pyspellchecker` ou `language-tool-python`
- Appliquer la correction apr√®s le nettoyage des pr√©fixes
- Corriger les erreurs courantes : "dran" ‚Üí "de", "lorsqueil" ‚Üí "lorsqu'il"

---

## üìù Plan d'Action

### Phase 1 : Corrections Critiques (Priorit√© üî¥)

1. **Corriger la synchronisation Texte/TTS**
   - Modifier `StreamingTextDisplay` pour stocker le texte complet
   - Modifier `_on_llm_complete()` pour r√©cup√©rer le texte complet
   - Utiliser ce texte pour le TTS

2. **Corriger la r√©p√©tition de la pr√©sentation**
   - Modifier le prompt syst√®me dans `system_config.py`
   - Ajouter un flag de premi√®re interaction dans `qaia_core.py`
   - Adapter le prompt selon le flag

3. **Corriger les doublons "(HH:MM) QAIA:"**
   - Am√©liorer le prompt pour interdire ces pr√©fixes
   - Renforcer le nettoyage (multi-passes, insensible √† la casse)
   - Ajouter un post-traitement final

### Phase 2 : Am√©liorations Qualit√© (Priorit√© üü°)

4. **Ajouter correcteur orthographique**
   - Installer `pyspellchecker` ou `language-tool-python`
   - Cr√©er une fonction de correction orthographique
   - L'appliquer apr√®s le nettoyage des pr√©fixes

5. **Unifier le flux de traitement**
   - Centraliser le post-traitement dans une fonction unique
   - S'assurer que le m√™me texte est utilis√© partout (affichage, TTS, logs)

---

## üéØ Crit√®res de Succ√®s

- ‚úÖ TTS lit exactement le m√™me texte que celui affich√©
- ‚úÖ Pas de r√©p√©tition de la pr√©sentation apr√®s la premi√®re interaction
- ‚úÖ Aucun doublon "(HH:MM) QAIA:" dans les r√©ponses
- ‚úÖ Fautes d'orthographe corrig√©es automatiquement
- ‚úÖ Flux de traitement coh√©rent et unifi√©

---

**Derni√®re mise √† jour** : 2025-12-22  
**Auteur** : Audit structurel automatique

