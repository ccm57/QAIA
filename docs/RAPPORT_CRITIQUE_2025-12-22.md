# Rapport Critique - 22 DÃ©cembre 2025

**Date** : 2025-12-22 18:42  
**Statut** : ğŸ”´ PROBLÃˆMES CRITIQUES NON RÃ‰SOLUS  
**PrioritÃ©** : ğŸ”´ URGENTE

---

## ğŸ“Š ANALYSE OBJECTIVE DES LOGS

### Logs ObservÃ©s (18:42-18:43)

```
2025-12-22 18:43:28,507 - TTS UI (streaming): dÃ©clenchement, longueur=109
2025-12-22 18:43:29,258 - TTS UI (streaming): lancÃ© (non bloquant)
2025-12-22 18:43:31,475 - TTS UI (streaming): dÃ©clenchement, longueur=109
2025-12-22 18:43:32,412 - TTS UI (streaming): lancÃ© (non bloquant)
2025-12-22 18:43:34,774 - TTS UI (streaming): dÃ©clenchement, longueur=109
2025-12-22 18:43:35,289 - TTS UI (streaming): lancÃ© (non bloquant)
```

**CONSTAT** : Le TTS est dÃ©clenchÃ© **3 fois** avec la mÃªme longueur (109 caractÃ¨res).

---

## ğŸ”´ PROBLÃˆMES IDENTIFIÃ‰S

### 1. TTS DÃ‰CLENCHÃ‰ 3 FOIS (CRITIQUE)

**SymptÃ´me** : Le TTS est appelÃ© 3 fois pour la mÃªme rÃ©ponse  
**Cause probable** : `_on_llm_complete()` est appelÃ© plusieurs fois OU plusieurs Ã©vÃ©nements `llm.complete` sont Ã©mis  
**Impact** : RÃ©pÃ©tition vocale, confusion utilisateur  
**Fichier concernÃ©** : `interface/qaia_interface.py` ligne 548-582

**HypothÃ¨ses** :
1. Plusieurs Ã©vÃ©nements `llm.complete` Ã©mis par le RAG agent
2. `_on_llm_complete()` appelÃ© plusieurs fois (abonnements multiples ?)
3. TTS dÃ©clenchÃ© Ã  la fois dans `_on_llm_complete()` ET ailleurs

**Code problÃ©matique** :
```python
# interface/qaia_interface.py:548
def _on_llm_complete(self, event_data: dict):
    # ...
    if cleaned_streamed:
        threading.Thread(target=_speak_streamed, args=(cleaned_streamed,), daemon=True).start()
```

---

### 2. DOUBLONS "(18:42) QAIA:" PERSISTANTS (CRITIQUE)

**SymptÃ´me** : `(18:42) QAIA: (18:42) QAIA: Bonjour Claude...`  
**Cause** : Les corrections dans `process_streamed_text()` ne sont PAS appliquÃ©es correctement  
**Impact** : Texte illisible, TTS rÃ©pÃ¨te les prÃ©fixes  
**Fichier concernÃ©** : `utils/text_processor.py`

**Analyse** :
- Les corrections ont Ã©tÃ© ajoutÃ©es dans `process_streamed_text()`
- MAIS le texte affichÃ© contient encore les doublons
- **HYPOTHÃˆSE** : Le texte n'est pas passÃ© par `process_streamed_text()` avant affichage

**VÃ©rification nÃ©cessaire** :
- Le texte streamÃ© est-il nettoyÃ© AVANT d'Ãªtre affichÃ© dans `StreamingTextDisplay` ?
- `_on_llm_token()` applique-t-il le nettoyage ?

---

### 3. PRÃ‰SENTATION RÃ‰PÃ‰TÃ‰E 3 FOIS (CRITIQUE)

**SymptÃ´me** : "Bonjour, je suis QAIA..." rÃ©pÃ©tÃ© 3 fois  
**Cause** : 
1. PrÃ©sentation au dÃ©marrage (bienvenue)
2. PrÃ©sentation dans la premiÃ¨re rÃ©ponse LLM
3. PrÃ©sentation rÃ©pÃ©tÃ©e dans les rÃ©ponses suivantes

**Impact** : VerbositÃ© excessive, frustration utilisateur  
**Fichiers concernÃ©s** :
- `interface/qaia_interface.py` ligne 1536 (bienvenue)
- `agents/llm_agent.py` ligne 169-179 (prompt systÃ¨me)
- `qaia_core.py` ligne 96-502 (flag `_first_interaction`)

**ProblÃ¨me identifiÃ©** :
- Le flag `_first_interaction` n'est PAS rÃ©initialisÃ© Ã  la fermeture
- L'historique de conversation n'est PAS vidÃ© Ã  la fermeture
- Ã€ la rÃ©ouverture, le systÃ¨me pense que c'est encore la premiÃ¨re interaction

---

### 4. NETTOYAGE INCOMPLET Ã€ LA FERMETURE (CRITIQUE)

**SymptÃ´me** : L'historique et les flags ne sont pas rÃ©initialisÃ©s  
**Cause** : `_on_closing()` ne nettoie pas l'historique ni `_first_interaction`  
**Impact** : Ã‰tat persistant entre les sessions, bugs accumulÃ©s  
**Fichier concernÃ©** : `interface/qaia_interface.py` ligne 637-678

**Code actuel** :
```python
def _on_closing(self):
    # ...
    # âŒ MANQUE : RÃ©initialisation _first_interaction
    # âŒ MANQUE : Vidage conversation_history
    # âŒ MANQUE : Appel qaia.clear_conversation()
```

**Code manquant** :
```python
if qaia is not None:
    qaia.clear_conversation()  # âŒ MANQUE
    qaia._first_interaction = True  # âŒ MANQUE (pour prochaine session)
```

---

## ğŸ” ANALYSE TECHNIQUE DÃ‰TAILLÃ‰E

### Flux de GÃ©nÃ©ration LLM

```
1. qaia_core.process_message()
   â””â”€> llm_agent.chat(is_first_interaction=self._first_interaction)
       â””â”€> rag_agent.process_query()
           â””â”€> StreamingCallback.on_llm_new_token()
               â””â”€> Event Bus 'llm.token'
                   â””â”€> qaia_interface._on_llm_token()
                       â””â”€> StreamingTextDisplay.append_token()
           â””â”€> StreamingCallback.on_llm_end()
               â””â”€> Event Bus 'llm.complete'
                   â””â”€> qaia_interface._on_llm_complete()
                       â””â”€> TTS dÃ©clenchÃ© (PROBLÃˆME ICI)
```

**Question** : Pourquoi `_on_llm_complete()` est-il appelÃ© 3 fois ?

**HypothÃ¨ses** :
1. **Plusieurs abonnements** : `event_bus.subscribe('llm.complete', ...)` appelÃ© plusieurs fois ?
2. **Plusieurs Ã©vÃ©nements** : Le RAG agent Ã©met plusieurs Ã©vÃ©nements `llm.complete` ?
3. **TTS multiple** : Le TTS est dÃ©clenchÃ© ailleurs aussi (dans `_process_text_thread()` ?)

---

### Flux de Nettoyage Texte

```
1. LLM gÃ©nÃ¨re: "(18:42) QAIA: (18:42) QAIA: Bonjour..."
2. StreamingCallback.on_llm_new_token()
   â””â”€> filter_streaming_token() (filtre les prÃ©fixes)
   â””â”€> Event Bus 'llm.token'
       â””â”€> _on_llm_token()
           â””â”€> append_token() (AFFICHE SANS NETTOYAGE ?)
3. StreamingCallback.on_llm_end()
   â””â”€> Event Bus 'llm.complete'
       â””â”€> _on_llm_complete()
           â””â”€> get_streamed_text() (rÃ©cupÃ¨re texte brut)
           â””â”€> process_streamed_text() (NETTOIE)
           â””â”€> TTS avec texte nettoyÃ©
```

**PROBLÃˆME** : Le texte est affichÃ© AVANT nettoyage dans `append_token()`

---

## âœ… CORRECTIONS NÃ‰CESSAIRES

### 1. EmpÃªcher TTS Multiple

**Action** : Ajouter un flag pour empÃªcher les appels TTS multiples

```python
def _on_llm_complete(self, event_data: dict):
    if getattr(self, '_tts_already_triggered', False):
        return  # DÃ©jÃ  dÃ©clenchÃ©
    self._tts_already_triggered = True
    # ... reste du code ...
    # RÃ©initialiser aprÃ¨s TTS
    self._tts_already_triggered = False
```

### 2. Nettoyer Texte AVANT Affichage

**Action** : Appliquer `filter_streaming_token()` dans `append_token()`

```python
def append_token(self, token: str):
    from utils.text_processor import filter_streaming_token
    filtered = filter_streaming_token(token)
    if filtered:
        # Afficher
```

### 3. RÃ©initialiser Ã‰tat Ã  la Fermeture

**Action** : Ajouter dans `_on_closing()`

```python
if qaia is not None:
    qaia.clear_conversation()
    qaia._first_interaction = True  # Pour prochaine session
```

### 4. VÃ©rifier Abonnements Multiples

**Action** : VÃ©rifier que `event_bus.subscribe()` n'est pas appelÃ© plusieurs fois

---

## ğŸ“‹ TODO LISTE PRIORITAIRE

### ğŸ”´ URGENT (Bloquant)

1. **EmpÃªcher TTS multiple** : Ajouter flag `_tts_already_triggered`
2. **Nettoyer texte avant affichage** : Appliquer `filter_streaming_token()` dans `append_token()`
3. **RÃ©initialiser Ã©tat Ã  la fermeture** : Ajouter `clear_conversation()` et `_first_interaction = True`
4. **VÃ©rifier abonnements** : S'assurer qu'il n'y a qu'un seul abonnement Ã  `llm.complete`

### ğŸŸ¡ IMPORTANT (Non bloquant mais critique)

5. **Logs dÃ©taillÃ©s** : Ajouter logs pour tracer les appels TTS
6. **Tests** : CrÃ©er tests pour vÃ©rifier qu'il n'y a qu'un seul appel TTS
7. **Documentation** : Documenter le flux complet de gÃ©nÃ©ration

---

## ğŸ¯ RÃ‰SULTAT ATTENDU

AprÃ¨s corrections :
- âœ… **1 seul appel TTS** par rÃ©ponse
- âœ… **Texte sans doublons** dans l'interface
- âœ… **PrÃ©sentation unique** au dÃ©marrage uniquement
- âœ… **Ã‰tat rÃ©initialisÃ©** Ã  chaque fermeture

---

**Date** : 2025-12-22  
**Auteur** : Audit automatique  
**Statut** : ğŸ”´ EN ATTENTE DE CORRECTIONS

